{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hieu565/Math-Score-Prediction/blob/main/Math_predictor_app_backend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BI0ml_Hr8SlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abcda839-4c26-4d13-b6d2-4c0cba914e89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# take files from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "d77d0026",
        "outputId": "b141607a-5df9-4348-a350-33c12512529e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%pip install skorch optuna streamlit -q"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/263.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m225.3/263.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m263.1/263.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit_code = \"\"\"\n",
        "# import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import joblib\n",
        "import optuna\n",
        "import streamlit as st\n",
        "\n",
        "# load from drive\n",
        "random_forest_model_path='/content/drive/MyDrive/model_stability_results/best_random_forest_model.joblib'\n",
        "optuna_nn_model_path = '/content/drive/MyDrive/model_stability_results/optuna_neural_network_model.pth'\n",
        "preprocessor = '/content/drive/MyDrive/model_stability_results/preprocessor.pkl'\n",
        "\n",
        "# run the file again\n",
        "import requests\n",
        "\n",
        "# Google Sheet URL and export format\n",
        "sheet_url = \"https://docs.google.com/spreadsheets/d/13f0_u9eZR8m7Ro36jfQCs35fGCWubqjwil3Jdfbkwao/edit?gid=0#gid=0\"\n",
        "export_url = sheet_url.replace('/edit?gid=', '/export?format=csv&gid=')\n",
        "\n",
        "# Download the CSV\n",
        "response = requests.get(export_url)\n",
        "response.raise_for_status() # Check for errors\n",
        "\n",
        "# Save the CSV to a file\n",
        "csv_file_path = \"student_data.csv\"\n",
        "with open(csv_file_path, \"w\") as f:\n",
        "    f.write(response.text)\n",
        "\n",
        "print(f\"Downloaded data to {csv_file_path}\")\n",
        "\n",
        "# Load the data from the downloaded CSV\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the first few rows to confirm\n",
        "st.write(data.head())\n",
        "\n",
        "# reconstruct optuna model\n",
        "class StudentNN(nn.Module):\n",
        "  def __init__(self, input_dim, hidden1 = 56, hidden2 = 27, dropout = 0.2): # Modified hidden layer sizes\n",
        "    super(StudentNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim, hidden1)\n",
        "    self.fc2 = nn.Linear(hidden1, hidden2)\n",
        "    self.fc3 = nn.Linear(hidden2, 1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = self.relu(self.fc2(x))\n",
        "    x = self.dropout(x)\n",
        "    return self.fc3(x)\n",
        "\n",
        "device = torch.device('cpu')  # (use CPU for deployment)\n",
        "\n",
        "# preprocess\n",
        "preprocessor = joblib.load('/content/drive/MyDrive/model_stability_results/preprocessor.pkl')\n",
        "\n",
        "# recontruct random forest\n",
        "rf_model = joblib.load('/content/drive/MyDrive/model_stability_results/best_random_forest_model.joblib')\n",
        "\n",
        "# get input_dim from the preprocessor\n",
        "# Try to get the number of features from the preprocessor using get_feature_names_out()\n",
        "try:\n",
        "    input_dim = len(preprocessor.get_feature_names_out())\n",
        "except (AttributeError, TypeError):\n",
        "    try:\n",
        "        # Create a dummy DataFrame with appropriate numerical data types\n",
        "        # Use np.zeros with float dtype to ensure numerical compatibility\n",
        "        dummy_input = pd.DataFrame(np.zeros((1, len(preprocessor.feature_names_in_))), columns=preprocessor.feature_names_in_)\n",
        "        input_dim = preprocessor.transform(dummy_input).shape[1]\n",
        "    except AttributeError:\n",
        "        # If the above doesn't work, you might need to manually define input_dim\n",
        "        raise ValueError(\"Could not determine input_dim from preprocessor. Please manually set it.\")\n",
        "\n",
        "\n",
        "nn_model = StudentNN(input_dim).to(device)\n",
        "nn_model.load_state_dict(torch.load(optuna_nn_model_path, map_location=device))\n",
        "nn_model.eval()\n",
        "\n",
        "# build hybrid model\n",
        "\n",
        "class HybridModel:\n",
        "  def __init__(self, preprocessor, rf_model, nn_model, device='cpu', weight_rf=1, weight_nn=0):\n",
        "        self.preprocessor = preprocessor\n",
        "        self.rf_model = rf_model\n",
        "        self.nn_model = nn_model\n",
        "        self.device = device\n",
        "        self.weight_rf = weight_rf\n",
        "        self.weight_nn = weight_nn\n",
        "\n",
        "  def predict(self, X):\n",
        "        # 1ï¸âƒ£ Preprocess input\n",
        "        X_processed = self.preprocessor.transform(X)\n",
        "\n",
        "        # 2ï¸âƒ£ Random Forest prediction\n",
        "        rf_pred = self.rf_model.predict(X_processed)\n",
        "\n",
        "        # 3ï¸âƒ£ Neural Network prediction\n",
        "        with torch.no_grad():\n",
        "            X_tensor = torch.tensor(X_processed, dtype=torch.float32).to(self.device)\n",
        "            nn_pred = self.nn_model(X_tensor).cpu().numpy().flatten()\n",
        "\n",
        "        # 4ï¸âƒ£ Combine both\n",
        "        final_pred = (self.weight_rf * rf_pred) + (self.weight_nn * nn_pred)\n",
        "        return final_pred\n",
        "\n",
        "hybrid_model = HybridModel(preprocessor, rf_model, nn_model, device=device)\n",
        "\n",
        "# build steamlit UI\n",
        "st.title(\"ğŸ“Š Student Performance Predictor\")\n",
        "\n",
        "st.write(\"Enter the student features below:\")\n",
        "\n",
        "# Feature input definitions\n",
        "feature_inputs = {\n",
        "    \"StudyHours\": st.slider(\"Study Hours\", 0.0, 24.0, 0.0, 0.5),\n",
        "    \"HomeworkCompletion\": st.selectbox(\"Homework Completion\", [\"0-20%\", \"20-40%\", \"40-60%\", \"60-80%\", \"80-100%\"]),\n",
        "    \"AttentionLevel\": st.selectbox(\"Attention Level\", [\"0-20%\", \"20-40%\", \"40-60%\", \"60-80%\", \"80-100%\"]),\n",
        "    \"LearningMethod\": st.multiselect(\"Learning Methods\", [\"Learn theory\", \"Do homework\", \"Discuss with friends\", \"Watch online videos\"]),\n",
        "    \"StudyRoutines\": st.selectbox(\"Study Routines\", [\"Every day\", \"Every week\", \"Only before test\"]),\n",
        "    \"HandleDifficultMethod\": st.multiselect(\"Handling Difficult Subjects\", [\"Use Internet or AI\", \"Assistance from teachers/friends\", \"Do on your own\", \"Give up\"])\n",
        "}\n",
        "\n",
        "# Convert inputs to DataFrame\n",
        "input_df = pd.DataFrame([feature_inputs])\n",
        "\n",
        "# Predict button\n",
        "if st.button(\"Predict Score\"):\n",
        "    prediction = hybrid_model.predict(input_df)\n",
        "    st.success(f\"Predicted Student Score: {prediction[0]:.2f}\")\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cFmrB989L8mN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"student_predictor_app.py\", \"w\") as f:\n",
        "    f.write(streamlit_code)"
      ],
      "metadata": {
        "id": "_kMuYnuXMhIl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "mNIJFDKChRMd",
        "outputId": "63fd30c9-a096-40b0-bed4-f95a405349dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data  student_predictor_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!ls\n",
        "!git init"
      ],
      "metadata": {
        "id": "qtxXFWmFhVXP",
        "outputId": "43cddc4a-a32c-4a83-fd70-d45efd2574d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "drive  sample_data  student_predictor_app.py\n",
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"Hieu565\"\n",
        "!git config --global user.email \"phamminhhieu0817@gmail.com\""
      ],
      "metadata": {
        "id": "E_P94DUYhjC0"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}